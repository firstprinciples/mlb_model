{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\nWARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Dropout, RNN, Reshape, Embedding, concatenate\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from keras_model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\\\data\\\\processed2\\\\processed_data2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['date', 'gameid'], inplace=True)\n",
    "df.reset_index(0, drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_final'] = df['event_final'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_final_code'] = df['event_final'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation = df[['inning', 'batting team', 'outs', 'visiting_score', 'home_score', 'first', 'second', 'third']].values\n",
    "batter = df['res batter'].astype('category').cat.codes.values\n",
    "pitcher = df['res pitcher'].astype('category').cat.codes.values\n",
    "balls = df['balls'].values\n",
    "strikes = df['strikes'].values\n",
    "fouls = df['fouls'].values\n",
    "outcome = df['event_final_code'].values\n",
    "outcome_onehot = pd.get_dummies(df['event_final_code']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation[:, 0] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['BOS201004040', 'ANA201004050', 'ARI201004050', ...,\n       'TEX201909290', 'TOR201909290', 'WAS201909290'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df.gameid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtBatCell(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, n_batters, n_pitchers, situation_size, states):\n",
    "        super(AtBatCell, self).__init__()\n",
    "        self.n_batters = n_batters\n",
    "        self.n_pitchers = n_pitchers\n",
    "        self.situation_size = situation_size\n",
    "        self.states = states\n",
    "        self.state_size = tf.TensorShape([self.n_batters + self.n_pitchers, states])\n",
    "\n",
    "    def build( self, input_shape ):\n",
    "        self.Wz = self.add_weight('input z',\n",
    "                                    shape=[self.states*2, self.situation_size])\n",
    "        self.Wr = self.add_weight('input r',\n",
    "                                    shape=[self.states*2, self.situation_size])\n",
    "        self.Wh = self.add_weight('input h',\n",
    "                                    shape=[self.states*2, self.situation_size])\n",
    "        self.Uz = self.add_weight('state z',\n",
    "                                    shape=[self.states*2, self.states*2],\n",
    "                                    initializer=tf.keras.initializers.Identity(gain=0.8))\n",
    "        self.Ur = self.add_weight('state r',\n",
    "                                    shape=[self.states*2, self.states*2],\n",
    "                                    initializer=tf.keras.initializers.Identity(gain=0.8))\n",
    "        self.Uh = self.add_weight('state h',\n",
    "                                    shape=[self.states*2, self.states*2],\n",
    "                                    initializer=tf.keras.initializers.Identity(gain=0.8))\n",
    "        self.bz = self.add_weight('const z',\n",
    "                                    shape=[self.states*2, 1],\n",
    "                                    initializer=tf.keras.initializers.Zeros)\n",
    "        self.br = self.add_weight('const r',\n",
    "                                    shape=[self.states*2, 1],\n",
    "                                    initializer=tf.keras.initializers.Ones())\n",
    "        self.bh = self.add_weight('const h',\n",
    "                                    shape=[self.states*2, 1],\n",
    "                                    initializer=tf.keras.initializers.Zeros)\n",
    "        super(AtBatCell, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, state):\n",
    "        x, b, p = inputs\n",
    "        x = tf.reshape(x, (-1, 1))\n",
    "        state = state[0] + tf.zeros((state[0].shape))\n",
    "        h = self.get_states(state, b, p)\n",
    "        hp = self.GRU(x, h)\n",
    "        state = self.update_states(state, b, p, hp, h)\n",
    "        state = tf.reshape(state, (1, state.shape[0], state.shape[1]))\n",
    "        return state, [state]\n",
    "\n",
    "    def GRU(self, x, h):\n",
    "        z = self.Wz @ x + self.Uz @ h + self.bz\n",
    "        z = tf.math.sigmoid(z)\n",
    "        r = self.Wr @ x + self.Ur @ h - self.br\n",
    "        r = tf.math.sigmoid(r)\n",
    "        m = self.Wh @ x + self.Uh @ (r * h) + self.bh\n",
    "        m = tf.math.tanh(m)\n",
    "        hp = z * h + (1-z) * m\n",
    "        return hp\n",
    "\n",
    "    def get_states(self, states, batter, pitcher):\n",
    "        state_batter = tf.gather_nd(states[0], batter)\n",
    "        state_pitcher = tf.gather_nd(states[0], pitcher)\n",
    "        h = tf.concat((state_batter, state_pitcher), axis=0)\n",
    "        return tf.reshape(h, (-1, 1))\n",
    "    \n",
    "    def update_states(self, states, batter, pitcher, hp, h):\n",
    "        dh = hp - h\n",
    "        dh = tf.reshape(dh, (2, -1))\n",
    "        indices = tf.reshape([batter, pitcher], (2, 1))\n",
    "        states = states[0] + tf.scatter_nd(indices, dh, states[0].shape)\n",
    "        return states\n",
    "\n",
    "class AtBatRNN(RNN):\n",
    "    \n",
    "    def __init__(self, n_batters, n_pitchers, situation_size, states, \n",
    "                 return_sequences=True, return_state=False,\n",
    "                 stateful=False, unroll=False):\n",
    "        self.n_batters = n_batters\n",
    "        self.n_pitchers = n_pitchers\n",
    "        self.situation_size = situation_size\n",
    "        self.states = states\n",
    "        cell = AtBatCell(n_batters, n_pitchers, situation_size, states)\n",
    "        super(AtBatRNN, self).__init__(cell, \n",
    "            return_sequences=return_sequences, return_state=return_state,\n",
    "            stateful=stateful, unroll=unroll)\n",
    "        \n",
    "    def call(self, inputs, initial_state=None, constants=None):\n",
    "        return super(AtBatRNN, self).call(inputs, initial_state=initial_state, constants=constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameRNN(RNN):\n",
    "    \n",
    "    def __init__(self, n_batters, n_pitchers, situation_size, states, \n",
    "                 return_sequences=True, return_state=False,\n",
    "                 stateful=True, unroll=False):\n",
    "        self.n_batters = n_batters\n",
    "        self.n_pitchers = n_pitchers\n",
    "        self.situation_size = situation_size\n",
    "        self.states = states\n",
    "        cell = AtBatRNN(n_batters, n_pitchers, situation_size, states)\n",
    "        super(GameRNN, self).__init__(cell, \n",
    "            return_sequences=return_sequences, return_state=return_state,\n",
    "            stateful=stateful, unroll=unroll)\n",
    "        \n",
    "    def call(self, inputs, initial_state=None, constants=None):\n",
    "        return super(GameRNN, self).call(inputs, initial_state=initial_state, constants=constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, situation_size, states, classes):\n",
    "        super(PredictionLayer, self).__init__()\n",
    "        self.situation_size = situation_size\n",
    "        self.states = states\n",
    "        self.classes = classes\n",
    "\n",
    "    def build( self, input_shape ):\n",
    "        self.W = self.add_weight('input',\n",
    "                                   shape=[self.classes, self.situation_size])\n",
    "        self.U = self.add_weight('state',\n",
    "                                   shape=[self.classes, self.states*2])\n",
    "        self.b = self.add_weight('const',\n",
    "                                   shape=[self.classes, 1])\n",
    "        super(PredictionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        xp, states, bp, pp = inputs\n",
    "        xp = tf.expand_dims(xp, axis=-1)\n",
    "        hp = self.get_states(states, bp, pp)\n",
    "        return self.W @ xp + self.U @ hp + self.b\n",
    "\n",
    "    def get_states(self, states, batters, pitchers):\n",
    "        seq_len = batters.shape[1]\n",
    "        seq_len_range = tf.expand_dims(tf.range(seq_len, dtype=tf.int32), axis=1)\n",
    "        batter_indices = tf.concat((seq_len_range, batters[0]),\n",
    "                                   axis=1)\n",
    "        pitcher_indices = tf.concat((seq_len_range, pitchers[0]),\n",
    "                                    axis=1)\n",
    "        state_batters = tf.gather_nd(states[0], batter_indices)\n",
    "        state_pitchers = tf.gather_nd(states[0], pitcher_indices)\n",
    "        h = tf.concat((state_batters, state_pitchers), axis=1)\n",
    "        return tf.reshape(h, (seq_len, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model( n_batters, n_pitchers, situation_size, emb, states, classes, seq_len, state_model=False ):\n",
    "    \n",
    "    '''\n",
    "    This function builds the tensorflow model.\n",
    "    '''\n",
    "    b = Input(batch_shape=(1, seq_len, 1), dtype=tf.int32)\n",
    "    p = Input(batch_shape=(1, seq_len, 1), dtype=tf.int32)\n",
    "    sit = Input(batch_shape=(1, seq_len, situation_size))\n",
    "    event = Input(batch_shape=(1, seq_len), dtype=tf.int32)\n",
    "    pitch = Input(batch_shape=(1, seq_len, 3))\n",
    "\n",
    "    ev = Embedding(classes, emb)(event)\n",
    "    ev = Reshape((seq_len, emb))(ev)\n",
    "\n",
    "    x = concatenate([sit, ev, pitch], axis=-1)\n",
    "\n",
    "    if state_model:\n",
    "        stateful = False\n",
    "    else:\n",
    "        stateful = True\n",
    "    \n",
    "    h_p = AtBatRNN(n_batters, n_pitchers, situation_size+emb+3, states, stateful=stateful)(tuple([x, b, p]))\n",
    "\n",
    "    if state_model:\n",
    "        return Model(inputs=[b, p, sit, event, pitch],\n",
    "                     outputs=[h_p])\n",
    "    \n",
    "    b_p = Input(batch_shape=(1, seq_len, 1), dtype=tf.int32)\n",
    "    p_p = Input(batch_shape=(1, seq_len, 1), dtype=tf.int32)\n",
    "    sit_p = Input(batch_shape=(1, seq_len, situation_size))\n",
    "    \n",
    "    result = PredictionLayer(situation_size, states, classes)([sit_p, h_p, b_p, p_p])\n",
    "    \n",
    "    result = Reshape((seq_len, -1))(result)\n",
    "\n",
    "    result = Activation('softmax')(result)\n",
    "\n",
    "    pitch_count = PredictionLayer(situation_size, states, 3)([sit_p, h_p, b_p, p_p])\n",
    "    \n",
    "    model = Model(inputs=[b, p, sit, event, pitch, b_p, p_p, sit_p],\n",
    "                  outputs=[result, pitch_count])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = range(2*840000)\n",
    "test = range(2*839995, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "range(0, 1680000)"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_start = [len(train)%seq_len + seq_len*i for i in range(len(train)//seq_len)]\n",
    "time_series = [range(start, start+seq_len) for start in seq_start]\n",
    "time_series_plus = [range(start+1, start+1+seq_len) for start in seq_start]\n",
    "seq_start_test = [test[0] + seq_len*i for i in range(len(test)//seq_len)]\n",
    "time_series_test = [range(start, start+seq_len) for start in seq_start_test]\n",
    "time_series_plus_test = [range(start+1, start+1+seq_len) for start in seq_start_test]\n",
    "# time_series_test = [range(len(test))]\n",
    "# time_series_plus_test = [range(1,len(test)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time_series(tensor, time_series_list):\n",
    "    tensor_list = []\n",
    "    for r in time_series_list:\n",
    "        tensor_list += [tensor[r]]\n",
    "    return np.stack(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_ex = np.expand_dims(batter, axis=1).astype(np.int32)\n",
    "pitcher_ex = np.expand_dims(pitcher + np.unique(batter).shape[0], axis=1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_batched = convert_to_time_series(situation, time_series)\n",
    "batters_batched = convert_to_time_series(batter_ex, time_series)\n",
    "pitchers_batched = convert_to_time_series(pitcher_ex, time_series)\n",
    "situation_batched_plus = convert_to_time_series(situation, time_series_plus)\n",
    "batters_batched_plus = convert_to_time_series(batter_ex, time_series_plus)\n",
    "pitchers_batched_plus = convert_to_time_series(pitcher_ex, time_series_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_count = np.concatenate(\n",
    "    (np.expand_dims(balls, axis=1), np.expand_dims(strikes, axis=1), np.expand_dims(fouls, axis=1)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_count_batched = convert_to_time_series(pitch_count, time_series)\n",
    "outcome_batched = convert_to_time_series(outcome, time_series)\n",
    "pitch_count_batched_plus = convert_to_time_series(pitch_count, time_series_plus)\n",
    "outcome_onehot_batched_plus = convert_to_time_series(outcome_onehot, time_series_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_batched_test = convert_to_time_series(situation, time_series_test)\n",
    "batters_batched_test = convert_to_time_series(batter_ex, time_series_test)\n",
    "pitchers_batched_test = convert_to_time_series(pitcher_ex, time_series_test)\n",
    "situation_batched_plus_test = convert_to_time_series(situation, time_series_plus_test)\n",
    "batters_batched_plus_test = convert_to_time_series(batter_ex, time_series_plus_test)\n",
    "pitchers_batched_plus_test = convert_to_time_series(pitcher_ex, time_series_plus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_count_batched_test = convert_to_time_series(pitch_count, time_series_test)\n",
    "outcome_batched_test = convert_to_time_series(outcome, time_series_test)\n",
    "pitch_count_batched_plus_test = convert_to_time_series(pitch_count, time_series_plus_test)\n",
    "outcome_onehot_batched_plus_test = convert_to_time_series(outcome_onehot, time_series_plus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batters = np.unique(batter).shape[0]\n",
    "n_pitchers = np.unique(pitcher).shape[0]\n",
    "situation_size = situation.shape[1]\n",
    "states = 12\n",
    "embedding_dim = 6\n",
    "classes = outcome_onehot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model( n_batters, n_pitchers, situation_size, embedding_dim, states, classes, seq_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, LR):\n",
    "    adam = tf.keras.optimizers.Adam(lr=LR)\n",
    "    model.compile(\n",
    "        optimizer=adam,\n",
    "        loss=['categorical_crossentropy', 'mean_squared_error'],\n",
    "        metrics=['accuracy', 'RootMeanSquaredError'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1d29fad0b48>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "model.load_weights('..\\\\models\\\\prediction_model_v2_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_model(model, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch: 1\nTrain on 210 samples\n210/210 [==============================] - 4418s 21s/sample - loss: 4.0765 - activation_loss: 3.3321 - prediction_layer_1_loss: 0.7444 - activation_accuracy: 0.1601 - activation_RootMeanSquaredError: 0.0911 - prediction_layer_1_accuracy: 0.4682 - prediction_layer_1_RootMeanSquaredError: 0.8628\nepoch: 2\nTrain on 210 samples\n210/210 [==============================] - 4369s 21s/sample - loss: 4.0763 - activation_loss: 3.3318 - prediction_layer_1_loss: 0.7444 - activation_accuracy: 0.1600 - activation_RootMeanSquaredError: 0.0911 - prediction_layer_1_accuracy: 0.4682 - prediction_layer_1_RootMeanSquaredError: 0.8628\nepoch: 3\nTrain on 210 samples\n  3/210 [..............................] - ETA: 1:15:37 - loss: 4.1482 - activation_loss: 3.3971 - prediction_layer_1_loss: 0.7511 - activation_accuracy: 0.1554 - activation_RootMeanSquaredError: 0.0913 - prediction_layer_1_accuracy: 0.4683 - prediction_layer_1_RootMeanSquaredError: 0.8667"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-1de11470af28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m               verbose=1)\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = '..\\\\models\\\\prediction_model_v2'\n",
    "for i in range(200):\n",
    "    print('epoch: '+str(i+1))\n",
    "    model.reset_states()\n",
    "    model.fit(x=[batters_batched, pitchers_batched, situation_batched, outcome_batched, pitch_count_batched,\n",
    "                 batters_batched_plus, pitchers_batched_plus, situation_batched_plus],\n",
    "              y=[outcome_onehot_batched_plus, pitch_count_batched_plus], \n",
    "              batch_size=1,\n",
    "              epochs=1,\n",
    "              verbose=1)\n",
    "    model.save_weights(model_name + '_' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('..\\\\models\\\\prediction_model_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(1, 8000)]          0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (1, 8000, 6)         678         input_4[0][0]                    \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            [(1, 8000, 8)]       0                                            \n__________________________________________________________________________________________________\nreshape (Reshape)               (1, 8000, 6)         0           embedding[0][0]                  \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            [(1, 8000, 3)]       0                                            \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (1, 8000, 17)        0           input_3[0][0]                    \n                                                                 reshape[0][0]                    \n                                                                 input_5[0][0]                    \n__________________________________________________________________________________________________\ninput_1 (InputLayer)            [(1, 8000, 1)]       0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(1, 8000, 1)]       0                                            \n__________________________________________________________________________________________________\ninput_8 (InputLayer)            [(1, 8000, 8)]       0                                            \n__________________________________________________________________________________________________\nat_bat_rnn (AtBatRNN)           (1, 8000, 4939, 12)  3024        concatenate[0][0]                \n                                                                 input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\ninput_6 (InputLayer)            [(1, 8000, 1)]       0                                            \n__________________________________________________________________________________________________\ninput_7 (InputLayer)            [(1, 8000, 1)]       0                                            \n__________________________________________________________________________________________________\nprediction_layer (PredictionLay (1, 8000, 113, 1)    3729        input_8[0][0]                    \n                                                                 at_bat_rnn[0][0]                 \n                                                                 input_6[0][0]                    \n                                                                 input_7[0][0]                    \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (1, 8000, 113)       0           prediction_layer[0][0]           \n__________________________________________________________________________________________________\nactivation (Activation)         (1, 8000, 113)       0           reshape_1[0][0]                  \n__________________________________________________________________________________________________\nprediction_layer_1 (PredictionL (1, 8000, 3, 1)      99          input_8[0][0]                    \n                                                                 at_bat_rnn[0][0]                 \n                                                                 input_6[0][0]                    \n                                                                 input_7[0][0]                    \n==================================================================================================\nTotal params: 7,530\nTrainable params: 7,530\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1d3c84ef748>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "state_model = build_model( n_batters, n_pitchers, situation_size, embedding_dim, states, classes, seq_len, True )\n",
    "state_model.load_weights('..\\\\models\\\\prediction_model_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = state_model.predict([batters_batched[-10:], pitchers_batched[-10:], situation_batched[-10:], outcome_batched[-10:], pitch_count_batched[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4939, 12)"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "state_final = state[-1, -1]\n",
    "state_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('..\\\\models\\\\prediction_model_v2_state', state_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = build_model( n_batters, n_pitchers, situation_size, embedding_dim, states, classes, seq_len )\n",
    "model_test.load_weights('..\\\\models\\\\prediction_model_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.layers[9].reset_states(states=np.expand_dims(state_final, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_preds = []\n",
    "pitch_count_preds = []\n",
    "for batch in range(batters_batched_test.shape[0]):\n",
    "    print(batch)\n",
    "    outcome_pred, pitch_count_pred = model_test([batters_batched_test.astype(np.int32)[batch:batch+1], pitchers_batched_test.astype(np.int32)[batch:batch+1], situation_batched_test.astype(np.float32)[batch:batch+1], outcome_batched_test.astype(np.int32)[batch:batch+1], pitch_count_batched_test.astype(np.float32)[batch:batch+1], batters_batched_plus_test.astype(np.int32)[batch:batch+1], pitchers_batched_plus_test.astype(np.int32)[batch:batch+1], situation_batched_plus_test.astype(np.float32)[batch:batch+1]])\n",
    "    outcome_preds += [outcome_pred.numpy()]\n",
    "    pitch_count_preds += [pitch_count_pred.numpy()]\n",
    "outcome_preds = np.stack(outcome_preds)\n",
    "pitch_count_preds = np.stack(pitch_count_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_pred = np.reshape(outcome_preds, (-1, outcome_preds.shape[-1]))\n",
    "pitch_count_pred = np.reshape(pitch_count_preds, (-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('..\\\\data\\\\processed2\\\\model_v1_preds\\\\outcomes', outcomes_pred)\n",
    "np.save('..\\\\data\\\\processed2\\\\model_v1_preds\\\\pitch_counts', pitch_count_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for layer in model_test.layers:\n",
    "    for weight in layer.trainable_weights:\n",
    "        print(weight.name)\n",
    "        plt.imshow(weight.numpy())\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sit_feed(X, outcome_dict):\n",
    "    sit_feed = {'inning' : int(round(X[0]) + 1),\n",
    "                'half inning' : int(round(X[1])),\n",
    "                'outs' : int(round(X[2])),\n",
    "                'visiting score' : int(round(X[3])),\n",
    "                'home score' : int(round(X[4])),\n",
    "                'first' : int(round(X[5])),\n",
    "                'second' : int(round(X[6])),\n",
    "                'third' : int(round(X[7]))}\n",
    "    return sit_feed\n",
    "\n",
    "def get_sit_out_test(y_test, ind):\n",
    "    test = [t[ind] for t in y_test]\n",
    "    sit_out = {'inning' : np.where(test[0])[0][0]+1,\n",
    "                'half inning' : int(round(test[1])),\n",
    "                'outs' : np.where(test[2])[0][0],\n",
    "                'visiting score' : np.where(test[3])[0][0],\n",
    "                'home score' : np.where(test[4])[0][0],\n",
    "                'first' : int(round(test[5])),\n",
    "                'second' : int(round(test[6])),\n",
    "                'third' : int(round(test[7]))}\n",
    "    return sit_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = df['event_final'].astype('category')\n",
    "bats = df['res batter'].astype('category')\n",
    "pits = df['res pitcher'].astype('category')\n",
    "\n",
    "outcome_dict = {}\n",
    "for i, cat in enumerate(cats.cat.categories):\n",
    "    outcome_dict[cat] = i\n",
    "outcome_dict_rev = dict(enumerate(cats.cat.categories))\n",
    "N_outcomes = len(outcome_dict)\n",
    "\n",
    "bat_dict = {}\n",
    "for i, bat in enumerate(bats.cat.categories):\n",
    "    bat_dict[cat] = i\n",
    "bat_dict_rev = dict(enumerate(bats.cat.categories))\n",
    "\n",
    "pit_dict = {}\n",
    "for i, pit in enumerate(pits.cat.categories):\n",
    "    pit_dict[cat] = i\n",
    "pit_dict_rev = dict(enumerate(pits.cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_order=df['event_final'].value_counts().index\n",
    "order = []\n",
    "for ev in ev_order:\n",
    "    order += [outcome_dict[ev]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 40020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sit_feed = get_sit_feed(situation_batched_test[ind // seq_len, ind % seq_len], outcome_dict_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sit_feed)\n",
    "print(bat_dict_rev[batters_batched_test[ind // seq_len, ind % seq_len][0]])\n",
    "print(pit_dict_rev[pitchers_batched_test[ind // seq_len, ind % seq_len][0]-np.unique(batter).shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 16,8\n",
    "plt.bar(np.arange(20), outcomes_pred[ind][np.array(order)[:20]])\n",
    "plt.xticks(np.arange(20), ev_order[:20])\n",
    "plt.title('Probability of event')\n",
    "plt.ylim([0, 0.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitretroconda5edbee28fa404aa59e7e2665892ecb3c",
   "display_name": "Python 3.7.6 64-bit ('retro': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}