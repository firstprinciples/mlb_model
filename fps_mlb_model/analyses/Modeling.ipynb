{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitretroconda5edbee28fa404aa59e7e2665892ecb3c",
   "display_name": "Python 3.7.6 64-bit ('retro': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Dropout, RNN\n",
    "from tensorflow.keras import Model\n",
    "from keras_model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\\\data\\\\processed2\\\\processed_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_final'] = df['event_final'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_final_code'] = df['event_final'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n11000\n12000\n13000\n14000\n15000\n16000\n17000\n18000\n19000\n20000\n21000\n22000\n23000\n24000\n25000\n26000\n27000\n28000\n29000\n30000\n31000\n32000\n33000\n34000\n35000\n36000\n37000\n38000\n39000\n40000\n41000\n42000\n43000\n44000\n45000\n46000\n47000\n48000\n49000\n50000\n51000\n52000\n53000\n54000\n55000\n56000\n57000\n58000\n59000\n60000\n61000\n62000\n63000\n64000\n65000\n66000\n67000\n68000\n69000\n70000\n71000\n72000\n73000\n74000\n75000\n76000\n77000\n78000\n79000\n80000\n81000\n82000\n83000\n84000\n85000\n86000\n87000\n88000\n89000\n90000\n91000\n92000\n93000\n94000\n95000\n96000\n97000\n98000\n99000\n100000\n101000\n102000\n103000\n104000\n105000\n106000\n107000\n108000\n109000\n110000\n111000\n112000\n113000\n114000\n115000\n116000\n117000\n118000\n119000\n120000\n121000\n122000\n123000\n124000\n125000\n126000\n127000\n128000\n129000\n130000\n131000\n132000\n133000\n134000\n135000\n136000\n137000\n138000\n139000\n140000\n141000\n142000\n143000\n144000\n145000\n146000\n147000\n148000\n149000\n150000\n151000\n152000\n153000\n154000\n155000\n156000\n157000\n158000\n159000\n160000\n161000\n162000\n163000\n164000\n165000\n166000\n167000\n168000\n169000\n170000\n171000\n172000\n173000\n174000\n175000\n176000\n177000\n178000\n179000\n180000\n181000\n182000\n183000\n184000\n185000\n186000\n187000\n188000\n189000\n190000\n191000\n192000\n193000\n194000\n195000\n196000\n197000\n198000\n199000\n200000\n201000\n202000\n203000\n204000\n205000\n206000\n207000\n208000\n209000\n210000\n211000\n212000\n213000\n214000\n215000\n216000\n217000\n218000\n219000\n220000\n221000\n222000\n223000\n224000\n225000\n226000\n227000\n228000\n229000\n230000\n231000\n232000\n233000\n234000\n235000\n236000\n237000\n238000\n239000\n240000\n241000\n242000\n243000\n244000\n245000\n246000\n247000\n248000\n249000\n250000\n251000\n252000\n253000\n254000\n255000\n256000\n257000\n258000\n259000\n260000\n261000\n262000\n263000\n264000\n265000\n266000\n267000\n268000\n269000\n270000\n271000\n272000\n273000\n274000\n275000\n276000\n277000\n278000\n279000\n280000\n281000\n282000\n283000\n284000\n285000\n286000\n287000\n288000\n289000\n290000\n291000\n292000\n293000\n294000\n295000\n296000\n297000\n298000\n299000\n300000\n301000\n302000\n303000\n304000\n305000\n306000\n307000\n308000\n309000\n310000\n311000\n312000\n313000\n314000\n315000\n316000\n317000\n318000\n319000\n320000\n321000\n322000\n323000\n324000\n325000\n326000\n327000\n328000\n329000\n330000\n331000\n332000\n333000\n334000\n335000\n336000\n337000\n338000\n339000\n340000\n341000\n342000\n343000\n344000\n345000\n346000\n347000\n348000\n349000\n350000\n351000\n352000\n353000\n354000\n355000\n356000\n357000\n358000\n359000\n360000\n361000\n362000\n363000\n364000\n365000\n366000\n367000\n368000\n369000\n370000\n371000\n372000\n373000\n374000\n375000\n376000\n377000\n378000\n379000\n380000\n381000\n382000\n383000\n384000\n385000\n386000\n387000\n388000\n389000\n390000\n391000\n392000\n393000\n394000\n395000\n396000\n397000\n398000\n399000\n400000\n401000\n402000\n403000\n404000\n405000\n406000\n407000\n408000\n409000\n410000\n411000\n412000\n413000\n414000\n415000\n416000\n417000\n418000\n419000\n420000\n421000\n422000\n423000\n424000\n425000\n426000\n427000\n428000\n429000\n430000\n431000\n432000\n433000\n434000\n435000\n436000\n437000\n438000\n439000\n440000\n441000\n442000\n443000\n444000\n445000\n446000\n447000\n448000\n449000\n450000\n451000\n452000\n453000\n454000\n455000\n456000\n457000\n458000\n459000\n460000\n461000\n462000\n463000\n464000\n465000\n466000\n467000\n468000\n469000\n470000\n471000\n472000\n473000\n474000\n475000\n476000\n477000\n478000\n479000\n480000\n481000\n482000\n483000\n484000\n485000\n486000\n487000\n488000\n489000\n490000\n491000\n492000\n493000\n494000\n495000\n496000\n497000\n498000\n499000\n500000\n501000\n502000\n503000\n504000\n505000\n506000\n507000\n508000\n509000\n510000\n511000\n512000\n513000\n514000\n515000\n516000\n517000\n518000\n519000\n520000\n521000\n522000\n523000\n524000\n525000\n526000\n527000\n528000\n529000\n530000\n531000\n532000\n533000\n534000\n535000\n536000\n537000\n538000\n539000\n540000\n541000\n542000\n543000\n544000\n545000\n546000\n547000\n548000\n549000\n550000\n551000\n552000\n553000\n554000\n555000\n556000\n557000\n558000\n559000\n560000\n561000\n562000\n563000\n564000\n565000\n566000\n567000\n568000\n569000\n570000\n571000\n572000\n573000\n574000\n575000\n576000\n577000\n578000\n579000\n580000\n581000\n582000\n583000\n584000\n585000\n586000\n587000\n588000\n589000\n590000\n591000\n592000\n593000\n594000\n595000\n596000\n597000\n598000\n599000\n600000\n601000\n602000\n603000\n604000\n605000\n606000\n607000\n608000\n609000\n610000\n611000\n612000\n613000\n614000\n615000\n616000\n617000\n618000\n619000\n620000\n621000\n622000\n623000\n624000\n625000\n626000\n627000\n628000\n629000\n630000\n631000\n632000\n633000\n634000\n635000\n636000\n637000\n638000\n639000\n640000\n641000\n642000\n643000\n644000\n645000\n646000\n647000\n648000\n649000\n650000\n651000\n652000\n653000\n654000\n655000\n656000\n657000\n658000\n659000\n660000\n661000\n662000\n663000\n664000\n665000\n666000\n667000\n668000\n669000\n670000\n671000\n672000\n673000\n674000\n675000\n676000\n677000\n678000\n679000\n680000\n681000\n682000\n683000\n684000\n685000\n686000\n687000\n688000\n689000\n690000\n691000\n692000\n693000\n694000\n695000\n696000\n697000\n698000\n699000\n700000\n701000\n702000\n703000\n704000\n705000\n706000\n707000\n708000\n709000\n710000\n711000\n712000\n713000\n714000\n715000\n716000\n717000\n718000\n719000\n720000\n721000\n722000\n723000\n724000\n725000\n726000\n727000\n728000\n729000\n730000\n731000\n732000\n733000\n734000\n735000\n736000\n737000\n738000\n739000\n740000\n741000\n742000\n743000\n744000\n745000\n746000\n747000\n748000\n749000\n750000\n751000\n752000\n753000\n754000\n755000\n756000\n757000\n758000\n759000\n760000\n761000\n762000\n763000\n764000\n765000\n766000\n767000\n768000\n769000\n770000\n771000\n772000\n773000\n774000\n775000\n776000\n777000\n778000\n779000\n780000\n781000\n782000\n783000\n784000\n785000\n786000\n787000\n788000\n789000\n790000\n791000\n792000\n793000\n794000\n795000\n796000\n797000\n798000\n799000\n800000\n801000\n802000\n803000\n804000\n805000\n806000\n807000\n808000\n809000\n810000\n811000\n812000\n813000\n814000\n815000\n816000\n817000\n818000\n819000\n820000\n821000\n822000\n823000\n824000\n825000\n826000\n827000\n828000\n829000\n830000\n831000\n832000\n833000\n834000\n835000\n836000\n837000\n838000\n839000\n840000\n841000\n842000\n843000\n844000\n845000\n846000\n847000\n848000\n849000\n850000\n851000\n852000\n853000\n854000\n855000\n856000\n857000\n858000\n859000\n860000\n861000\n862000\n863000\n864000\n865000\n866000\n867000\n868000\n869000\n870000\n871000\n872000\n873000\n874000\n875000\n876000\n877000\n878000\n879000\n880000\n881000\n882000\n883000\n884000\n885000\n886000\n887000\n888000\n889000\n890000\n891000\n892000\n893000\n894000\n895000\n896000\n897000\n898000\n899000\n900000\n901000\n902000\n903000\n904000\n905000\n"
    }
   ],
   "source": [
    "first = [0]*len(df)\n",
    "second = [0]*len(df)\n",
    "third = [0]*len(df)\n",
    "for i in df.index:\n",
    "    if isinstance(df.loc[i, '1st runner'], str):\n",
    "        first[i] = 1\n",
    "    if isinstance(df.loc[i, '2nd runner'], str):\n",
    "        second[i] = 1\n",
    "    if isinstance(df.loc[i, '3rd runner'], str):\n",
    "        third[i] = 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "first = np.array(first)\n",
    "second = np.array(second)\n",
    "third = np.array(third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first'] = first\n",
    "df['second'] = second\n",
    "df['third'] = third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation = df[['inning', 'batting team', 'outs', 'visiting_score', 'home_score', 'first', 'second', 'third']].values\n",
    "batter = df['res batter'].astype('category').cat.codes.values\n",
    "pitcher = df['res pitcher'].astype('category').cat.codes.values\n",
    "balls = df['balls'].values\n",
    "strikes = df['strikes'].values\n",
    "fouls = df['fouls'].values\n",
    "outcome = df['event_final_code'].values\n",
    "outcome_onehot = pd.get_dummies(df['event_final_code']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation[:, 0] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtBatCell(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, n_batters, n_pitchers, situation_size, states):\n",
    "        super(AtBatCell, self).__init__()\n",
    "        self.n_batters = n_batters\n",
    "        self.n_pitchers = n_pitchers\n",
    "        self.situation_size = situation_size\n",
    "        self.states = states\n",
    "        self.state_size = tf.TensorShape([self.n_batters + self.n_pitchers, states])\n",
    "\n",
    "    def build( self, input_shape ):\n",
    "        self.Wz = self.add_weight('input z',\n",
    "                                    shape=[self.states*2, self.situation_size])\n",
    "        self.Wr = self.add_weight('input r',\n",
    "                                    shape=[self.states*2, self.situation_size])\n",
    "        self.Wh = self.add_weight('input h',\n",
    "                                    shape=[self.states*2, self.situation_size])\n",
    "        self.Uz = self.add_weight('state z',\n",
    "                                    shape=[self.states*2, self.states*2])\n",
    "        self.Ur = self.add_weight('state r',\n",
    "                                    shape=[self.states*2, self.states*2])\n",
    "        self.Uh = self.add_weight('state h',\n",
    "                                    shape=[self.states*2, self.states*2])\n",
    "        self.bz = self.add_weight('const z',\n",
    "                                    shape=[self.states*2, 1])\n",
    "        self.br = self.add_weight('const r',\n",
    "                                    shape=[self.states*2, 1])\n",
    "        self.bh = self.add_weight('const h',\n",
    "                                    shape=[self.states*2, 1])\n",
    "        super(AtBatCell, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, state):\n",
    "        x, b, p = inputs\n",
    "        x = tf.reshape(x, (-1, 1))\n",
    "        state = state[0] + tf.zeros((state[0].shape))\n",
    "        h = self.get_states(state, b, p)\n",
    "        hp = self.GRU(x, h)\n",
    "        state = self.update_states(state, b, p, hp, h)\n",
    "        state = tf.reshape(state, (1, state.shape[0], state.shape[1]))\n",
    "        return state, [state]\n",
    "\n",
    "    def GRU(self, x, h):\n",
    "        z = self.Wz @ x + self.Uz @ h + self.bz\n",
    "        z = tf.math.sigmoid(z)\n",
    "        r = self.Wr @ x + self.Ur @ h + self.br\n",
    "        r = tf.math.sigmoid(r)\n",
    "        m = self.Wh @ x + self.Uh @ (r * h) + self.bh\n",
    "        m = tf.math.tanh(m)\n",
    "        hp = z * h + (1-z) * m\n",
    "        return hp\n",
    "\n",
    "    def get_states(self, states, batter, pitcher):\n",
    "        state_batter = tf.gather_nd(states[0], batter)\n",
    "        state_pitcher = tf.gather_nd(states[0], pitcher)\n",
    "        h = tf.concat((state_batter, state_pitcher), axis=0)\n",
    "        return tf.reshape(h, (-1, 1))\n",
    "    \n",
    "    def update_states(self, states, batter, pitcher, hp, h):\n",
    "        dh = hp - h\n",
    "        dh = tf.reshape(dh, (2, -1))\n",
    "        indices = tf.reshape([batter, pitcher], (2, 1))\n",
    "        states = states[0] + tf.scatter_nd(indices, dh, states[0].shape)\n",
    "        return states\n",
    "\n",
    "class AtBatRNN(RNN):\n",
    "    \n",
    "    def __init__(self, n_batters, n_pitchers, situation_size, states, \n",
    "                 return_sequences=True, return_state=False,\n",
    "                 stateful=True, unroll=False):\n",
    "        self.n_batters = n_batters\n",
    "        self.n_pitchers = n_pitchers\n",
    "        self.situation_size = situation_size\n",
    "        self.states = states\n",
    "        cell = AtBatCell(n_batters, n_pitchers, situation_size, states)\n",
    "        super(AtBatRNN, self).__init__(cell, \n",
    "            return_sequences=return_sequences, return_state=return_state,\n",
    "            stateful=stateful, unroll=unroll)\n",
    "        \n",
    "    def call(self, inputs, initial_state=None, constants=None):\n",
    "        return super(AtBatRNN, self).call(inputs, initial_state=initial_state, constants=constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, n_batters, n_pitchers, situation_size, states, classes):\n",
    "        super(PredictionLayer, self).__init__()\n",
    "        self.n_batters = n_batters\n",
    "        self.n_pitchers = n_pitchers\n",
    "        self.situation_size = situation_size\n",
    "        self.states = states\n",
    "        self.classes = classes\n",
    "\n",
    "    def build( self, input_shape ):\n",
    "        self.W = self.add_weight('input',\n",
    "                                   shape=[self.classes, self.situation_size])\n",
    "        self.U = self.add_weight('state',\n",
    "                                   shape=[self.classes, self.states*2])\n",
    "        self.b = self.add_weight('const',\n",
    "                                   shape=[self.classes, 1])\n",
    "        super(PredictionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        xp, states, bp, pp = inputs\n",
    "        xp = tf.expand_dims(xp, axis=-1)\n",
    "        hp = self.get_states(states, bp, pp)\n",
    "        return self.W @ xp + self.U @ hp + self.b\n",
    "\n",
    "    def get_states(self, states, batters, pitchers):\n",
    "        seq_len = batters.shape[1]\n",
    "        state_batters = tf.gather_nd(states[0], batters)\n",
    "        state_pitchers = tf.gather_nd(states[0], pitchers)\n",
    "        h = tf.concat((state_batters, state_pitchers), axis=1)\n",
    "        return tf.reshape(h, (seq_len, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model( n_batters, n_pitchers, situation_size, states, output_shape, seq_len ):\n",
    "    \n",
    "    '''\n",
    "    This function builds the tensorflow model.\n",
    "    '''\n",
    "    b = Input(batch_shape=(1, seq_len, 1), dtype=tf.int32)\n",
    "    p = Input(batch_shape=(1, seq_len, 1), dtype=tf.int32)\n",
    "    x = Input(batch_shape=(1, seq_len, situation_size))\n",
    "    \n",
    "    h_p = AtBatRNN(n_batters, n_pitchers, situation_size, states)(tuple([x, b, p]))\n",
    "    \n",
    "    b_p = Input(batch_shape=(None, seq_len, 1), dtype=tf.int32)\n",
    "    p_p = Input(batch_shape=(None, seq_len, 1), dtype=tf.int32)\n",
    "    x_p = Input(batch_shape=(None, seq_len, situation_size))\n",
    "    \n",
    "    result = PredictionLayer(n_batters, n_pitchers, situation_size, states, output_shape)([x_p, h_p, b_p, p_p])\n",
    "    \n",
    "    result = Activation('softmax')(result)\n",
    "\n",
    "    pitch_count = PredictionLayer(n_batters, n_pitchers, situation_size, states, output_shape)([x_p, h_p, b_p, p_p])\n",
    "    \n",
    "    model = Model(inputs=[b, p, x, b_p, p_p, x_p],\n",
    "                  outputs=[result, pitch_count])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = range(840000)\n",
    "test = range(840000, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_start = [len(train)%seq_len + seq_len*i for i in range(len(train)//seq_len)]\n",
    "time_series = [range(start, start+seq_len) for start in seq_start]\n",
    "time_series_plus = [range(start+1, start+1+seq_len) for start in seq_start]\n",
    "time_series_test = [range(len(test))]\n",
    "time_series_test_plus = [range(1,len(test)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time_series(tensor, time_series_list):\n",
    "    tensor_list = []\n",
    "    for r in time_series_list:\n",
    "        tensor_list += [tensor[r]]\n",
    "    return np.stack(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "batter = np.expand_dims(batter, axis=1).astype(np.float32)\n",
    "pitcher = np.expand_dims(pitcher, axis=1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_batched = convert_to_time_series(situation, time_series)\n",
    "batters_batched = convert_to_time_series(batter, time_series)\n",
    "pitchers_batched = convert_to_time_series(pitcher, time_series)\n",
    "situation_batched_plus = convert_to_time_series(situation, time_series_plus)\n",
    "batters_batched_plus = convert_to_time_series(batter, time_series_plus)\n",
    "pitchers_batched_plus = convert_to_time_series(pitcher, time_series_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_count = np.concatenate(\n",
    "    (np.expand_dims(balls, axis=1), np.expand_dims(strikes, axis=1), np.expand_dims(fouls, axis=1)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_count_batched = convert_to_time_series(pitch_count, time_series_plus)\n",
    "outcome_onehot_batched = convert_to_time_series(outcome_onehot, time_series_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batters = np.unique(batter).shape[0]\n",
    "n_pitchers = np.unique(pitcher).shape[0]\n",
    "situation_size = situation.shape[1]\n",
    "states = 8\n",
    "classes = outcome_onehot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model( n_batters, n_pitchers, situation_size, states, classes, seq_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, LR):\n",
    "    adam = tf.keras.optimizers.Adam(lr=LR)\n",
    "    model.compile(\n",
    "        optimizer=adam,\n",
    "        loss=['categorical_crossentropy', 'mean_squared_error'],\n",
    "        metrics=['accuracy', 'RootMeanSquaredError'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_model(model, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch: 1\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_31 to have 3 dimensions, but got array with shape (420, 2000, 1, 1, 1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-0e325b618b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m               verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\retro\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_31 to have 3 dimensions, but got array with shape (420, 2000, 1, 1, 1)"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print('epoch: '+str(i+1))\n",
    "    model.fit(x=[batters_batched, pitchers_batched, situation_batched,\n",
    "                 batters_batched_plus, pitchers_batched_plus, situation_batched_plus],\n",
    "              y=[pitch_count_batched, outcome_onehot_batched], \n",
    "              batch_size=1,\n",
    "              epochs=1,\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}